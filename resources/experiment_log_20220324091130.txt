{"ENCODER_INPUT_WIDTH": 255, "ENCODER_INPUT_HEIGHT": 255, "LATENT_SPACE_SIZE": 8, "LEARNING_RATE": 1e-06, "EPOCHS": 100, "BATCH_SIZE": 32, "DATA_PATH": "E:\\Pictures", "ARCHITECTURE": "Sequential(\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n  (3): AvgPool2d(kernel_size=3, stride=3, padding=0)\n  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): LeakyReLU(negative_slope=0.01, inplace=True)\n  (7): AvgPool2d(kernel_size=3, stride=3, padding=0)\n  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (10): LeakyReLU(negative_slope=0.01, inplace=True)\n  (11): AvgPool2d(kernel_size=3, stride=3, padding=0)\n  (12): Flatten(start_dim=1, end_dim=-1)\n  (13): Linear(in_features=10368, out_features=1024, bias=True)\n  (14): Linear(in_features=1024, out_features=8, bias=True)\n  (15): Tanh()\n)", "NOTES": "Previous approach with a larger number of channels in the encoder seemed to let the network pick up on color and style patterns, \n\t\tbut this isn't exactly what we'd hoped for at this point.  It's still useful.  Perhaps part of the problem is that it's flipping horizontally and vertically the image at random\n\t\tand having some problems matching up with this level of corruption.  Maybe it's overfitting, which would be hard given the procedural nature of the data, \n\t\tbut the dataset is still kinda' small.  First, reduce the number of channels and the latent space so we have a good 'color vibe' encoder and then train for\n\t\tfewer epochs.  A smaller model that does the embedding will still be useful."}