{"ENCODER_INPUT_WIDTH": 255, "ENCODER_INPUT_HEIGHT": 255, "LATENT_SPACE_SIZE": 8, "LEARNING_RATE": 1e-06, "EPOCHS": 10, "BATCH_SIZE": 32, "DATA_PATH": "/home/joseph/512/", "ARCHITECTURE": "Sequential(\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): LeakyReLU(negative_slope=0.01, inplace=True)\n  (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (10): LeakyReLU(negative_slope=0.01, inplace=True)\n  (11): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n  (12): Flatten(start_dim=1, end_dim=-1)\n  (13): Linear(in_features=10368, out_features=1024, bias=True)\n  (14): Linear(in_features=1024, out_features=1024, bias=True)\n  (15): Linear(in_features=1024, out_features=8, bias=True)\n  (16): Tanh()\n)", "NOTES": "What happens if we use max pool instead of avg pool?  Next test we can check the hypercube instead of the hypersphere.", "TRAINING_LOSSES": [9347.587890215218, 7930.556749459356, 7474.901351701468, 7249.756702749059, 7161.29033542797, 7064.047124035656, 6996.563586937264, 6952.015612754971, 6893.045192195103, 6864.938983615488]}